# 3. 内存管理

常用概念: 

- 页框：内存中固定长度的快
- 页：固定长度的数据库，存储在二级存储器中（如磁盘）。数据页可以临时赋值到内存的页框中。
- 段：变长数据块，存储在二级存储器中。整个段可以临时复制到内存的一个可用区域中（分段），或可以将一个段分为许多页，然后将每页单独复制到内存中（分段与分页相结合）



内存管理的主要操作是处理器把程序装入内存中执行。内存管理的功能有：
1、内存空间的分配与回收：由操作系统完成主存储器空间的分配和管理，使程序员摆脱存储分配的麻烦，提高编程效率。
2、地址转换：在多道程序环境下，程序中的逻辑地址与内存中的物理地址不可能一致，因此存储管理必须提供地址变换功能，把逻辑地址转换成相应的物理地址。
3、内存空间的扩充：利用虚拟存储技术或自动覆盖技术，从逻辑上扩充内存。
4、存储保护：保证各道作业在各自的存储空间内运行，互不干扰。



进程对应的内存空间中所包含的5种不同的数据区：  

- 代码段(code segment):又称文本段，用来存放指令，运行代码的一块内存空间。此空间大小在代码运行前就已经确定。内存空间一般属于只读，某些架构的代码也允许可写。

- 数据段(data segment): 存储初始化的全局变量和初始化的static变量。数据段中的数据的生存期是随程序持续性(随进程持续性):进程创建就存在，进程死亡就消失。

- BSS段(bss segment)：存储未初始化的全局变量和未初始化的static变量。bss段中数据的生存期随进程持续性。bss段中的数据一般默认为0.
- rodata段:只读数据 比如 printf 语句中的格式字符串和开关语句的跳转表。也就是常量区。例如，全局作用域中的 const int ival = 10，ival  存放在 .rodata 段；再如，函数局部作用域中的 printf("Hello world %d\n", c); 语句中的格式字符串  "Hello world %d\n"，也存放在 .rodata 段。

- 堆（heap）：堆是用于存放进程运行中被动态分配的内存段，它的大小并不固定，可动态扩张或缩减。当进程调用malloc、realloc等函数分配内存时，新分配的内存就被动态添加到堆上（堆被扩张）；当利用free等函数释放内存时，被释放的内存从堆中被剔除（堆被缩减）

- 栈(stack):栈是用户存放程序临时创建的局部变量，也就是说我们函数括弧“{}”中定义的变量（但不包括static声明的变量，static意味着在数据段中存放变量）。栈的生存期随代码块持续性，代码块运行就给你分配空间，代码块结束就自动回收空间。除此以外，在函数被调用时，其参数也会被压入发起调用的进程栈中，并且待到调用结束后，函数的返回值也会被存放回栈中。由于栈的先进先出特点，所以栈特别方便用来保存/恢复调用现场。从这个意义上讲，我们可以把堆栈看成一个寄存、交换临时数据的内存区。

上述几种内存区域中数据段、BSS和堆通常是被连续存储的——内存位置上是连续的，而代码段和栈往往会被独立存放。有趣的是，堆和栈两个区域关系很“暧昧”，他们一个向下“长”（i386体系结构中栈向下、堆向上），一个向上“长”，相对而生。但你不必担心他们会碰头，因为他们之间间隔很大（到底大到多少，你可以从下面的例子程序计算一下），绝少有机会能碰到一起。



## 内存的演变

在早些的操作系统中，并没有引入内存抽象的概念。程序直接访问和操作的都是物理内存，内存的管理也非常简单，除去操作系统所用的内存之外，全部给用户程序使用，想怎么折腾都行，只要别超出最大的容量。这种内存操作方式使得操作系统中存在多进程变得完全不可能，比如MS-DOS，你必须执行完一条指令后才能接着执行下一条。如果是多进程的话，由于直接操作物理内存地址，当一个进程给内存地址1000赋值后，另一个进程也同样给内存地址赋值，那么第二个进程对内存的赋值会覆盖第一个进程所赋的值，这回造成两条进程同时崩溃。随着计算机技术发展，要求操作系统支持多进程的需求，所谓多进程，并不需要同时运行这些进程，只要它们都处于 ready  状态，操作系统快速地在它们之间切换，就能达到同时运行的假象。每个进程都需要内存，Context Switch  时，之前内存里的内容怎么办？简单粗暴的方式就是先 dump 到磁盘上，然后再从磁盘上 restore 之前 dump  的内容（如果有的话），但效果并不好，太慢了！那怎么才能不慢呢？把进程对应的内存依旧留在物理内存中，需要的时候就切换到特定的区域。这就涉及到了内存的保护机制，毕竟进程之间可以随意读取、写入内容就乱套了，非常不安全。因此操作系统需要对物理内存做一层抽象，也就是「地址空间」(Address Space)，一个进程的地址空间包含了该进程所有相关内存，比如 code / stack / heap。一个 16 KB  的地址空间可能长这样：

![img](https://raw.githubusercontent.com/CharonChui/Pictures/master/memory_1.jpg?raw=true)

Stack 和 Heap 中间有一块 free space，即使没有用，也被占着，那如何才能解放这块区域呢，进入虚拟内存。



Linux操作系统采用虚拟内存管理技术，使得每个进程都有各自互不干涉的进程地址空间。该空间是块大小为4G的线性虚拟空间，用户所看到和接触到的都是该虚拟地址，无法看到实际的物理内存地址。利用这种虚拟地址不但能起到保护操作系统的效果（用户不能直接访问物理内存），而且更重要的是，用户程序可使用比实际物理内存更大的地址空间（具体的原因请看硬件基础部分）。

在讨论进程空间细节前，这里先要澄清下面几个问题：

l     第一、4G的进程地址空间被人为的分为两个部分——用户空间与内核空间。用户空间从0到3G（0xC0000000），内核空间占据3G到4G。用户进程通常情况下只能访问用户空间的虚拟地址，不能访问内核空间虚拟地址。只有用户进程进行系统调用（代表用户进程在内核态执行）等时刻可以访问到内核空间。

l     第二、用户空间对应进程，所以每当进程切换，用户空间就会跟着变化；而内核空间是由内核负责映射，它并不会跟着进程改变，是固定的。内核空间地址有自己对应的页表（init_mm.pgd），用户进程各自有不同的页表。

l     第三、每个进程的用户空间都是完全独立、互不相干的。不信的话，你可以把上面的程序同时运行10次（当然为了同时运行，让它们在返回前一同睡眠100秒吧），你会看到10个进程占用的线性地址一模一样。



![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWFnZXMyMDE3LmNuYmxvZ3MuY29tL2Jsb2cvMTMxMTQxMi8yMDE4MDIvMTMxMTQxMi0yMDE4MDIxNTEyMjY1NDM1OS0xNDcxMTE4NzM4LnBuZw?x-oss-process=image/format,png)



### 固定分区



大多数内存管理方案都假定操作系统占据内存中的某些固定部分，而内存中的其余部分则供多个用户进程使用。管理用户内存空间的最简单的方案就是对它分区，以形成若干边界固定的区域。

固定分区分为两种： 

- 使用大小相等的分区：此时小于等于分区大小的任何进程都可以装入任何可用的分区中。若所有分区都已满且没有进程处于就绪态或运行态，则操作系统可以换出一个进程的所有分区，并装入另一个进程，使得处理器有事可做。但是大小相等的分区有两个难点： 

    - 程序可能太大而不能放到一个分区中。此时程序员必须使用覆盖技术设计程序，使得任何时候该程序只有一部分需要放到内存中。当需要的模块不在时，用户程序必须把这个模块装入程序的分区，覆盖该分区中的任何程序和数据。

    - 内存的利用率非常低。任何程序，急事很小，都需要占据一个完整的分区。由于装入的数据块小于分区大小，因而导致分区内部存在空间浪费，这种现象称为内部碎片(internal fragmentation)。

- 使用大小不等的分区：大小不等的分区可以缓解上面的两个问题，但是不能完全解决。

虽然大小不等的分区带来了一定的灵活性，但是分区的数量在系统生成阶段已经确定，因而限制了系统中活动（未挂起）进程的数量。而且由于分区大小是在系统生成阶段事先设置的，因而小作业不能有效的利用分区空间。



### 动态分区

为了克服固定分区的确定，提出了动态分区。对于动态分区，分区长度和数量是可变的。程序装入内存时，系统会给它分配一块与其所需容量完全相等的内存空间。但是对于一个64MB的内存，如果装入前三个进程已经占用了很大一部分，剩下的部分对于第四个进程来说又太小，这样在内存的末尾就剩下一个“空洞”。而等第二个进程结束后腾出的足够的空间来装入第四个进程，但是由于第四个进程比第二个进程小，所有这里又形成了另一个小"空洞"。这样最终在内存中就会形成许多小空洞。随着时间的推移，内存中形成了越来越多的碎片，内存的利用率随之下降。这种现象称为外部碎片(external fragmentation)，指在所有分区外的存储空间变成了越来越多的碎片，这与前面所讲的内部碎片正好对应。 

客服外部碎片的一种技术就是压缩(compaction)。操作系统不时的移动进程，使得进程占用的空间连续，并使所有空闲空间连成一片。但是压缩的困难之处在于，它是一个非常费时的过程，且会浪费处理器时间。



### 伙伴系统

固定分区和动态分区方案都有缺陷。固定分区方案限制了活动进程数量，且如果可用分区的大小与进程大小很不匹配，那么内存空间的利用率会非常低。动态分区的维护特别复杂，并且会引入进行压缩的额外开销。更有吸引力的一种折中方案是伙伴系统。 



### 重定位



在大小相等的分区中一个进程在其声明周期中可能占据不同的分区。首次创建一个进程映像时，它被装入内存中的摸个分区。以后该进程可能被换出，当它再次被换入时，可能被指定到与上一次不同的分区中。动态分区也存在同样的情况，压缩后内存中的进程也可能发生移动。因此，进程访问（指令和数据单元）的位置不是固定的。进程被换入或在内存中移动时，指令和数据单元的位置也发生变化。为了解决这个问题，需要区分几种地址类型： 

- 逻辑地址（logical address）是指与当前数据再内存中的物理分配地址无关的访问地址，在执行对内存的访问之前必须把它转换为物理地址。
- 相对地址（relative address）是逻辑地址的一个特例，他是相对于某些已知点（通常是程序的开始处）的存储单元。
- 物理地址（physical address）或绝对地址是数据在内存中的实际位置。

系统采用运行时动态加载的方式把使用相对地址的程序加载到内存。通常情况下，被加载进程中所有内存访问都相对于程序的开始点。因此，在执行包括这类访问的指令时，需要有把相对地址转换为物理内存地址的硬件机制。这类地址转换就需要一个特殊的处理器寄存器（基址寄存器），其内容是程序在内存中的起始地址。还有一个界限寄存器指明程序的终止位置。



### 分页

大小不等的固定分区和大小可变的分区技术在内存的使用上都是低效的，前者会产生内部碎片，后者会产生外部碎片。但是，如果内存被划分成大小固定、相等的块，切块相对比较小，每个进程也被分成同样大小的小块，那么进程中称为页的块可以分配到内存中称为页框的可用块。这样在使用分页技术时，每个进程在内存中浪费的空间，仅仅是进程最后一页的一小部分形成的内部碎片。没有任何外部碎片。

这样操作系统需要为每个进程维护一个页表（page table）。页表给出了该进程的每页所对应页框的位置。在程序中每个逻辑地址包括一个页号和该页中的偏移量。在分页中，逻辑地址到物理地址的转换仍然由处理器硬件完成，给出逻辑地址（页号，偏移量）后，处理器使用页表产生物理地址（页框号，偏移量）。



![img](https://raw.githubusercontent.com/CharonChui/Pictures/master/page_memory_1.png?raw=true)

采用分页技术的分区相当小，一个程序可以占据多个分区，并且这些分区不需要是连续的。

为了使分页方案更加方便，规定页和页框的大小必须是2的幂，以便容易的表示出相对地址。



### 分段

细分用户程序的另一种可选方案是分段。采用分段技术，可以把程序和与其相关的数据划分到几个段（fragment）中。尽管短有最大长度限制，但并不要求所有程序的所有段的长度都相等。和分页一样，采用分段技术时的逻辑地址也是由两部分组成：段号和偏移量。 

由于使用大小不等的段，分段类似于动态分区。在未采用覆盖方案或使用虚存的情况下，为执行一个程序，需要把它的所有段都装入内存。与动态分区不同的是，在分段方案中，一个程序可以占据多个分区，并且这些分区不要求是连续的。分段消除了内部碎片，但是和动态分区一样，他会产生外部碎片。不过由于进程被分成多个小块，因此外部碎片也会很小。

采用大小不等的段的另一个结果是，逻辑地址和物理地址间不再是简单的对应关系。类似于分页，在简单的分段方案中，每个进程都有一个段表，系统也会维护一个内存中的空闲块列表。每个段表都必须给出相应段在内存中的起始地址，还必须指明段的长度，以确保不会使用无效地址。





分页和分段的两个特点: 

- 进程中的所有内存访问的都是逻辑地址，这些逻辑地址会在运行时动态地址转换为物理地址。这意味着一个进程可被换入或换出内存，因此进程可在执行过程中的不同时刻占据内存中的不同区域。
- 一个进程可划分为许多块（页和段），在执行过程中，这些块不需要连续的位于内存中。动态运行时地址转换和页表或段表的使用使得这一点成为可能。

由于上面这两个特点的存在，那么在一个进程的执行过程中，该进程不需要所有页或段都在内存中。如果内存中保存有待取的下一条指令所在块（段或页）及待访问的下一个数据单元所在块，那么执行至少可以暂时继续下去。我们用术语“块”来表示页或段。处理器在需要访问一个不在内存中的逻辑地址时，会产生一个中断，这表明出现了内存访问故障。操作系统会把被中断的进程置于堵塞态。要继续执行这个进程，操作系统必须把包含引发访问故障的逻辑地址的进程块读入内存。为此操作系统产生一个磁盘I/O读请求。产生I/O请求后，在执行磁盘I/O期间，操作系统可以调度另一个进程运行。在需要的块读入内存后，产生一个I/O中断，控制权交回给操作系统，而操作系统则把由于缺少该块而被堵塞的进程置为就绪态。这样的话就会有两种提高系统利用率的方法: 

- 在内存中保留多个进程。由于对任何特定的进程都仅装入它的某些块，因此有足够的空间来放置更多的进程。这样，在任何时刻这些进程中至少有一个处于就绪态，于是处理器就得到了更有效的利用。
- 进程可以比内存的全部空间还大。程序占用的内存空间的大小是程序设计的最大限制之一。没有这种方案时，程序员必须清楚的知道有多少内存空间可用。若编写的程序太大，程序员就必须设计出能把程序分成块的方法，这些块可按某种覆盖策略分别加载。通过基于分页或分段的虚拟内存，这项工作可由操作系统和硬件完成。对程序员而言，他所处理的是一个巨大的内存，大小与磁盘存储器有关。操作系统在需要时会自动的把进程块装入内存。 

由于进程只能在内存中执行，因此这个存储器成为实存储器（real memory），简称实存。但程序员或用户感觉到的是一个更大的内存，且通常分配在磁盘上，这称为虚拟内存（virtual memory），简称虚存。虚存支持更有效的系统并发度，并能解除用户与内存之间没有必要的紧密约束。 



![img](https://raw.githubusercontent.com/CharonChui/Pictures/master/page_vs_fragment.png?raw=true)





## 虚拟内存

面对越来越大的程序,常常产生程序>内存的问题,为解决这种问题,虚拟内存的概念得到普及.

要有效的使用处理器和I/O设备，就需要在内存中保留尽可能多的进程。此外，还需要解除程序在开发时对程序使用内存大小的限制。解决这两个问题的途径就是虚拟内存技术。采用虚拟内存技术时，所有的地址访问都是逻辑访问，并在运行时转换为实地址。

虚拟内存机制使得期望运行大于物理内存的程序称为可能。其方法是将程序放在磁盘上，而将主存作为一种缓存，用来保存最频繁使用的部分程序。这种机制需要快速的映像内存地址，以便把程序生成的地址转换为有关字节在RAM中的物理地址。这种映像由CPU中的一个称为存储器管理单元（Memory Management Unit，MMU）的部件来完成。

**虚拟内存**的**基本思想**是:每个程序都拥有自己的地址空间,这个空间被分割成多个 块,每个块被成为一页或页面.

**程序运行时,并不是所有页都在物理内存中**:

- 当程序引用一部分在物理内存的地址空间时,由硬件直接执行必要的映射;
- 当程序引用一部分不在物理内存的地址空间时,有操作系统将缺失的页装入物理内存,并重新运行

虚拟内存基于分段和分页这两种基本技术或基于这两种技术中的一种。虚拟内存机制允许程序以逻辑方式访问存储器，而不考虑物理内存上可用的空间数量。虚存的构想是为了满足有多个用户作业同时驻留在内存中的要求，因此在一个进程被写出到副主存储器中且后续进程被读入时，连续的进程执行之间将不会脱节。进程大小不同时，若处理器在很多进程间切换，则很难把它们紧密的压入内存，因此人们引入了分页系统。在分页系统中，进程由许多固定大小的块组成。这些块成为页。程序通过虚地址(virtual address)访问，虚地址由页号和页中的偏移量组成。进程的每页都可置于内存中的任何地方，分页系统提供了程序中使用的虚地址和内存中的实地址(real address)或物理地址之间的动态映射。



### 分页访问过程:

1. CPU中包含**MMU内存管理单元**,用于管理虚拟地址空间到物理内存地址的映射.
2. 假设物理内存地址大小为32k,每4k为一个页框.虚拟地址空间分页,每个页面大小等于一个页框
3. 当程序想要访问一个虚拟地址x,
4. 指令将x送到MMU,
5. MMU根据x的虚拟地址,判断其对应的页面是否在物理内存中:
6. 若在,MMU将x转化为物理内存地址y
7. 若不在,则进行缺页中断,操作系统在物理内存中找到一个使用较少的页面回收掉,将需要访问的页面读到被回收的页面处,再将x转化为物理内存地址访问





### 虚拟内存的操作系统策略

#### 1. 读取策略

读取策略决定某页何时取入内存，常用的方法有如下两种：  

- 请求分页

    只有当访问到某页中的一个单元时才将改页取入内存。若内存管理的其他策略比较合适，将发生下述情况：当一个进程首次启动时，会在一段时间出现大量的缺页中断，取入越来越多的页后，局部性原理表明大多数将来访问的页都是最近去读的页。因此在一段时间后错误会逐渐减少，缺页中断的数量会降低到很低。

- 预先分页

    对于预先分页，读取的页并不是缺页中断请求的页。预先分页利用了大多数辅存设备（如磁盘）的特性，这些设备有寻道时间和合理的延迟。若一个进程的页连续存储在辅存中，则一次读取许多连续的页要比隔一段时间读取一页有效。当然，若大多数额外读取的页未引用到，则这个策略是低效的。进程首次启动时，可采用预先分页策略，此时程序员须以某种方式制定需要的页。

#### 2. 放置策略

防止策略决定一个进程块驻留在实存中的什么位置。在纯分页系统或段页式系统中，如何放置通常无关紧要，因为地址转换硬件和内存访问硬件能以相同的效率为任何页框组合执行相应的功能。

#### 3. 置换策略

以便处理在必须读取一个新页时，应该置换内存中的哪一页。当内存中的所有页框都被占据，且需要读取一个新页以处理一次缺页中断时，置换策略决定置换当前内存中的哪一页。所有策略的目标都是移出最近最不能访问的页。



#### 4. 驻留集管理

对于分页式虚拟内存，在准备执行时，不需要也不可能把一个进程的所有页都读入内存。因此，操作系统必须决定读取多少页，即决定给特定的进程分配多大的内存空间。



#### 5.清楚策略

与读取策略相反，清楚策略用于确定何时将已修改的一页写回辅存。通常有两种选择： 

- 请求式清楚

    只有当一页被选择用于置换时才能被写回辅存。

- 预约式清楚

    将这些已修改的多页在需要使用他们所占据的页框之前成批写回辅存。

#### 6.加载控制

加载控制会影响到驻留内存中的进程数量，这称为系统并发度。加载控制策略在有效的内存管理中非常重要。如果某一时刻驻留的进程太少，那么所有进程都处于堵塞态的概率就较大，因为会有许多时间话费在交换上。另一方面，如果驻留的进程太多，平均每个进程的驻留集大小将会不够用，此时会频繁发生缺页中断，从而导致系统抖动。





## Android内存管理

Android包含了标准Linux内核中内存管理设施的许多扩展，具体如下: 

- ASHMem：这个功能提供匿名共享内存，它将内存抽象为文件描述符。文件描述符可以传递给另一个进程以共享内存。
- Pmen：这个功能分配虚拟内存，使的它在物理上是连续的，因此对于那些不支持虚拟内存的设备非常实用。
- Low Memory Killer：大部分移动设备不具备置换能力（因为闪存的使用寿命因素）。主存耗尽时，使用大量内存的应用不是让步对内存的使用就是被终结。这个功能可让系统通知应用释放内存，如果应用不配合，则终结应用。


























---

- 邮箱 ：charon.chui@gmail.com  
- Good Luck! 
